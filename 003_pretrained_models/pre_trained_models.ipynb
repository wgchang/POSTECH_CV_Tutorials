{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from nets import vgg\n",
    "from utils.utils import *\n",
    "from utils.tf_utils import *\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "image_size = vgg.vgg_16.default_image_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 딥 러닝이 여러 분야에서 높은 성능으로 각광을 받고 있지만, 이는 ImageNet과 같은 빅 데이터의 출현에 힘입어 이뤄진 일로 딥 러닝으로 높은 성능을 내기 위해서는 충분한 양의 학습 데이터가 필요하다. 특히, detection, segmentation 등의 task는 classification보다 고수준의 annotation이 필요하기에 충분한 데이터를 모은다는 건 굉장한 노력과 비용을 필요로 한다. 하지만, classification을 위해 ImageNet에서 학습 된 네트워크는 물체를 컴퓨터가 인식하기에 적합한 feature를 추출하므로 다른 task에서 좋은 시작점으로 사용될 수 있고, 결과적으로 상대적으로 적은 데이터로 높은 성능을 낼 수 있는 모델을 학습하는 데 큰 도움이 된다. <br><br>\n",
    " 이번 튜토리얼에서는 ImageNet에서 학습된 vgg 16-layer 네트워크를 선언하고 checkpoint로부터 weight를 가져오는 방법을 공부해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download pre-trained model (vgg-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = 'vgg_models'\n",
    "data_url = 'http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz'\n",
    "maybe_download_and_extract(data_url, data_dir, 'vgg_16.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model\n",
    "vgg 네트워크를 선언하고, checkpoint로부터 가져올 weight를 정해보자.\n",
    "vgg 네트워크를 스스로 선언해도 되지만, 그러기 위해서는 checkpoint에 정의된 variable들과 name이 같도록 선언해야하므로 여기에서는 TF-Slim에서 제공하는 vgg 네트워크 선언 함수 (vgg.vgg_16())을 사용하여 네트워크를 정의하고, tf.contrib.slim.get_variables_to_restore()을 통해 checkpoint로부터 가져 올 weight를 정하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> The list of variables to be restored:\n",
      "vgg_16/conv1/conv1_1/weights\n",
      "vgg_16/conv1/conv1_1/biases\n",
      "vgg_16/conv1/conv1_2/weights\n",
      "vgg_16/conv1/conv1_2/biases\n",
      "vgg_16/conv2/conv2_1/weights\n",
      "vgg_16/conv2/conv2_1/biases\n",
      "vgg_16/conv2/conv2_2/weights\n",
      "vgg_16/conv2/conv2_2/biases\n",
      "vgg_16/conv3/conv3_1/weights\n",
      "vgg_16/conv3/conv3_1/biases\n",
      "vgg_16/conv3/conv3_2/weights\n",
      "vgg_16/conv3/conv3_2/biases\n",
      "vgg_16/conv3/conv3_3/weights\n",
      "vgg_16/conv3/conv3_3/biases\n",
      "vgg_16/conv4/conv4_1/weights\n",
      "vgg_16/conv4/conv4_1/biases\n",
      "vgg_16/conv4/conv4_2/weights\n",
      "vgg_16/conv4/conv4_2/biases\n",
      "vgg_16/conv4/conv4_3/weights\n",
      "vgg_16/conv4/conv4_3/biases\n",
      "vgg_16/conv5/conv5_1/weights\n",
      "vgg_16/conv5/conv5_1/biases\n",
      "vgg_16/conv5/conv5_2/weights\n",
      "vgg_16/conv5/conv5_2/biases\n",
      "vgg_16/conv5/conv5_3/weights\n",
      "vgg_16/conv5/conv5_3/biases\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "batch_size = 10\n",
    "checkpoint_path = 'vgg_models/vgg_16.ckpt'\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "# input placeholders\n",
    "images = tf.placeholder(dtype=tf.float32, shape=[batch_size, image_size, image_size, 3],\n",
    "                           name='images')\n",
    "labels = tf.placeholder(dtype=tf.int64, shape=[batch_size], name='labels')\n",
    "\n",
    "# Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "    # 10 classes instead of 1001.\n",
    "    logits, _ = vgg.vgg_16(images, num_classes=num_classes, is_training=True)\n",
    "\n",
    "# Before defining remaining layers (softmax, optimizer), selecting the\n",
    "# variables to be restored\n",
    "exclude_layers = ['vgg_16/fc6', 'vgg_16/fc7', 'vgg_16/fc8']\n",
    "#exclude_layers = ['vgg_16/fc8'] # when discaring only the last classification layer\n",
    "variables_to_restore = slim.get_variables_to_restore(exclude=exclude_layers)\n",
    "print('===> The list of variables to be restored:')\n",
    "for i in variables_to_restore: print(i.op.name)\n",
    "\n",
    "\"\"\"\n",
    "# Below code is equivalent to slim.get_variables_to_restore()\n",
    "exclusions = [scope.strip() for scope in exclude_layers]\n",
    "\n",
    "variables_to_restore = []\n",
    "for var in tf.global_variables():\n",
    "    excluded = False\n",
    "    for exclusion in exclusions:\n",
    "        if var.op.name.startswith(exclusion):\n",
    "            excluded = True\n",
    "            break\n",
    "    if not excluded:\n",
    "        variables_to_restore.append(var) \n",
    "\"\"\"\n",
    "\n",
    "# Define the loss function\n",
    "probabilities = tf.nn.softmax(logits)\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=labels, logits=logits, name='cross_entropy_per_example')\n",
    "\n",
    "# Specify the optimizer and create the train op:\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네트워크를 선언하였으니 tf.train.Saver()를 이용하여 checkpoint로부터 weight를 읽어오자.<br>\n",
    "위에서 convolutional layer들의 weight만 읽어오도록 하였으므로 아래에서 처음엔 모든 weight를 랜덤으로 초기화한 후, vgg checkpoint로부터 weight를 읽어와서 conv1_1과 fc7의 weight가 어떻게 프린트되는 지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the saver with variables to be restored\n",
    "restorer = tf.train.Saver(variables_to_restore)\n",
    "# Open the session\n",
    "sess = tf.Session()\n",
    "conv1_1_weights = tf.get_default_graph().get_tensor_by_name('vgg_16/conv1/conv1_1/weights:0')\n",
    "fc7_weights = tf.get_default_graph().get_tensor_by_name('vgg_16/fc7/weights:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight of conv1_1:\n",
      "[-0.06183929 -0.03114004 -0.08775672 -0.00964408  0.0169952  -0.00359296\n",
      "  0.05429178  0.01242758  0.07776228  0.08395071]\n",
      "Weight of fc7:\n",
      "[  1.10718589e-02   1.43526811e-02   1.79001484e-02  -2.61634178e-02\n",
      "   2.50892732e-02   2.06239615e-02   5.19613735e-03  -1.34535339e-02\n",
      "  -7.20545650e-05  -2.08393931e-02]\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "rand_conv1_1 = conv1_1_weights[:,:,:,:].eval(session=sess)\n",
    "rand_fc7 = fc7_weights[:,:,:,:].eval(session=sess)\n",
    "\n",
    "print('Weight of conv1_1:')\n",
    "print(rand_conv1_1[1,1,1,:10])\n",
    "print('Weight of fc7:')\n",
    "print(rand_fc7[0,0,0,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the weights from vgg-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight of conv1_1:\n",
      "[ 0.04063221  0.06581022  0.2203114  -0.42466447  0.20586449 -0.23609307\n",
      " -0.04312737 -0.10727409 -0.33554825 -0.09185937]\n",
      "Weight of fc7:\n",
      "[  1.10718589e-02   1.43526811e-02   1.79001484e-02  -2.61634178e-02\n",
      "   2.50892732e-02   2.06239615e-02   5.19613735e-03  -1.34535339e-02\n",
      "  -7.20545650e-05  -2.08393931e-02]\n"
     ]
    }
   ],
   "source": [
    "restorer.restore(sess, save_path=checkpoint_path)\n",
    "vgg_conv1_1 = conv1_1_weights[:,:,:,:].eval(session=sess)\n",
    "vgg_fc7 = fc7_weights[:,:,:,:].eval(session=sess)\n",
    "\n",
    "print('Weight of conv1_1:')\n",
    "print(vgg_conv1_1[1,1,1,:10])\n",
    "print('Weight of fc7:')\n",
    "print(vgg_fc7[0,0,0,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('difference in conv1_1: ', 4.4200602)\n",
      "('difference in fc7: ', 0.0)\n"
     ]
    }
   ],
   "source": [
    "print('difference in conv1_1: ',np.sum(rand_conv1_1 - vgg_conv1_1))\n",
    "print('difference in fc7: ', np.sum(rand_fc7 - vgg_fc7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 함수는 nets/vgg.py에 정의된 vgg 16-layer 네트워크 정의 함수로 참고용으로 첨부하였음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_16(inputs,\n",
    "           num_classes=1000,\n",
    "           is_training=True,\n",
    "           dropout_keep_prob=0.5,\n",
    "           spatial_squeeze=True,\n",
    "           scope='vgg_16',\n",
    "           fc_conv_padding='VALID'):\n",
    "    \"\"\"Oxford Net VGG 16-Layers version D Example.\n",
    "    Note: All the fully_connected layers have been transformed to conv2d layers.\n",
    "        To use in classification mode, resize input to 224x224.\n",
    "    Args:\n",
    "    inputs: a tensor of size [batch_size, height, width, channels].\n",
    "    num_classes: number of predicted classes.\n",
    "    is_training: whether or not the model is being trained.\n",
    "    dropout_keep_prob: the probability that activations are kept in the dropout\n",
    "      layers during training.\n",
    "    spatial_squeeze: whether or not should squeeze the spatial dimensions of the\n",
    "      outputs. Useful to remove unnecessary dimensions for classification.\n",
    "    scope: Optional scope for the variables.\n",
    "    fc_conv_padding: the type of padding to use for the fully connected layer\n",
    "      that is implemented as a convolutional layer. Use 'SAME' padding if you\n",
    "      are applying the network in a fully convolutional manner and want to\n",
    "      get a prediction map downsampled by a factor of 32 as an output. Otherwise,\n",
    "      the output prediction map will be (input / 32) - 6 in case of 'VALID' padding.\n",
    "    Returns:\n",
    "    the last op containing the log predictions and end_points dict.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope, 'vgg_16', [inputs]) as sc:\n",
    "        end_points_collection = sc.name + '_end_points'\n",
    "        # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
    "                            outputs_collections=end_points_collection):\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "            # Use conv2d instead of fully_connected layers.\n",
    "            net = slim.conv2d(net, 4096, [7, 7], padding=fc_conv_padding, scope='fc6')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n",
    "                             scope='dropout6')\n",
    "            net = slim.conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "            net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n",
    "                             scope='dropout7')\n",
    "            net = slim.conv2d(net, num_classes, [1, 1],\n",
    "                            activation_fn=None,\n",
    "                            normalizer_fn=None,\n",
    "                            scope='fc8')\n",
    "            \n",
    "        # Convert end_points_collection into a end_point dict.\n",
    "        end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "        if spatial_squeeze:\n",
    "        net = tf.squeeze(net, [1, 2], name='fc8/squeezed')\n",
    "        end_points[sc.name + '/fc8'] = net\n",
    "        return net, end_points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
