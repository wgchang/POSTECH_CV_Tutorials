{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# local python package\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from voc_loader import VOC_loader\n",
    "import fcn_vgg\n",
    "from loss import loss as get_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_result(img, gt_seg, pred_seg, palette):\n",
    "    if pred_seg is None:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    else:\n",
    "        f, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "        \n",
    "    ax1.imshow(img.astype(np.uint8))\n",
    "    ax2.imshow(gt_seg.astype(np.uint8))\n",
    "    \n",
    "    if pred_seg is not None:\n",
    "        np.place(pred_seg, pred_seg == 21, 255)\n",
    "        tmp = Image.fromarray(pred_seg.astype(np.uint8), 'P')\n",
    "        tmp.putpalette(palette)\n",
    "        ax3.imshow(tmp)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download VOC 2012 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('VOCdevkit'):\n",
    "    os.system('wget http://cvlab.postech.ac.kr/~jonghwan/VOC2012.tar')\n",
    "    os.system('tar xvf VOC2012.tar')\n",
    "    os.system('rm VOC2012.tar')\n",
    "\n",
    "if not os.path.isfile('vgg16.npy'):\n",
    "    os.system('wget http://cvlab.postech.ac.kr/~jonghwan/vgg16.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loader_params = {\n",
    "    'num_classes': 22,\n",
    "    'image_size': 448,\n",
    "    'split_root': 'VOCdevkit/VOC2012/ImageSets/Segmentation',\n",
    "    'image_root': 'VOCdevkit/VOC2012/JPEGImages',\n",
    "    'segmap_root': 'VOCdevkit/VOC2012/SegmentationClass',\n",
    "}\n",
    "loader = VOC_loader(loader_params)\n",
    "\n",
    "# get information for VOC\n",
    "class_names = loader.get_class_names()\n",
    "num_classes = loader_params['num_classes']\n",
    "img_size = loader_params['image_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = loader.get_batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bi = np.random.randint(10)\n",
    "plot_result(batch['images'][bi], batch['seg_maps'][bi], \n",
    "            None, loader.get_palette())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model updating parameters\n",
    "lr_params = {}\n",
    "lr_params['initial_lr'] = 0.0001\n",
    "lr_params['decay_step'] = 10000\n",
    "lr_params['decay_rate'] = 0.8\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 50\n",
    "save_path = 'fcn_checkpoints/fcn_vgg'\n",
    "if not os.path.exists('fcn_checkpoints'): os.makedirs('fcn_checkpoints')\n",
    "iteration_per_epoch = int(math.floor(loader.get_num_train_examples() / batch_size))\n",
    "save_checkpoint_frequency = 100\n",
    "print_frequency = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with tf.Session() as sess:\n",
    "with tf.variable_scope('inputs') as scope:\n",
    "    images = tf.placeholder(dtype=tf.float32, \n",
    "                            shape=[batch_size, img_size, img_size, 3],\n",
    "                            name='images')\n",
    "    labels = tf.placeholder(dtype=tf.int64, \n",
    "                            shape=[batch_size, img_size, img_size], \n",
    "                            name='labels')\n",
    "\n",
    "# build FCN\n",
    "vgg_fcn = fcn_vgg.FCN()\n",
    "with tf.name_scope(\"content_vgg\"):\n",
    "    vgg_fcn.build(images, train=True, num_classes=22, debug=False)\n",
    "    \n",
    "# optimizer\n",
    "global_step = tf.Variable(initial_value=0, name='global_step', trainable=False)\n",
    "lr = tf.train.exponential_decay(lr_params['initial_lr'],\n",
    "                                global_step,\n",
    "                                lr_params['decay_step'],\n",
    "                                lr_params['decay_rate'],\n",
    "                                staircase=True)\n",
    "total_loss = get_loss(vgg_fcn.upscore, labels, num_classes)\n",
    "train_op = tf.train.AdamOptimizer(lr).minimize(total_loss, global_step=global_step)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Manually set the checkpoint path\n",
    "#checkpoint_path = 'cifar10_checkpoints/cifar10_cnn-5000'\n",
    "# Automatically find the last checkpoint\n",
    "checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir='fcn_checkpoints/')\n",
    "print('Last checkpoint path is %s' % (checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create saver\n",
    "saver = tf.train.Saver()\n",
    "if checkpoint_path != '':\n",
    "    saver.restore(sess, save_path=checkpoint_path)\n",
    "    print('Model is restored from %s' % checkpoint_path)\n",
    "\n",
    "# create summary node and file wirter\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter('./log_train', sess.graph)\n",
    "\n",
    "for ie in range(num_epochs):\n",
    "    for ii in range(iteration_per_epoch):\n",
    "        # Load a batch data\n",
    "        batch = loader.get_batch(batch_size, 'train')\n",
    "        feed_dict = {images: batch['images'], labels: batch['seg_labels']}\n",
    "\n",
    "        # Run the optimizer\n",
    "        tensors = [global_step, merged, total_loss, train_op]\n",
    "        iteration, summary, tf_loss, _ = sess.run(tensors, feed_dict=feed_dict)\n",
    "        train_writer.add_summary(summary, iteration)\n",
    "\n",
    "        # Print the accuracy and loss of current batch data\n",
    "        if iteration % print_frequency == 0:\n",
    "            print('%d Epoch %d iteration - Loss (%.3f)' % (ie+1, ii+1, tf_loss))\n",
    "\n",
    "        # Save checkpoint\n",
    "        if iteration % save_checkpoint_frequency == 0:\n",
    "            saver.save(sess, save_path=save_path, global_step=global_step)\n",
    "            print('Saved checkpoint %s_%d' % (save_path, iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset the graph and session\n",
    "tf.reset_default_graph()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 7\n",
    "with tf.variable_scope('inputs') as scope:\n",
    "    images = tf.placeholder(dtype=tf.float32, \n",
    "                            shape=[batch_size, img_size, img_size, 3],\n",
    "                            name='images')\n",
    "    labels = tf.placeholder(dtype=tf.int64, \n",
    "                            shape=[batch_size, img_size, img_size], \n",
    "                            name='labels')\n",
    "\n",
    "# build FCN\n",
    "vgg_fcn = fcn_vgg.FCN()\n",
    "with tf.name_scope(\"content_vgg\"):\n",
    "    vgg_fcn.build(images, train=False, num_classes=22, debug=False)\n",
    "    \n",
    "# optimizer\n",
    "global_step = tf.Variable(initial_value=0, name='global_step', trainable=False)\n",
    "lr = tf.train.exponential_decay(lr_params['initial_lr'],\n",
    "                                global_step,\n",
    "                                lr_params['decay_step'],\n",
    "                                lr_params['decay_rate'],\n",
    "                                staircase=True)\n",
    "total_loss = get_loss(vgg_fcn.upscore, labels, num_classes)\n",
    "train_op = tf.train.AdamOptimizer(lr).minimize(total_loss, global_step=global_step)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Automatically find the last checkpoint\n",
    "#checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir='fcn_checkpoints/')\n",
    "checkpoint_path = 'fcn_checkpoints/cifar10_cnn-3000'\n",
    "print('Last checkpoint path is %s' % (checkpoint_path))\n",
    "# Create saver\n",
    "saver = tf.train.Saver()\n",
    "if checkpoint_path != '':\n",
    "    saver.restore(sess, save_path=checkpoint_path)\n",
    "    print('Model is restored from %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loader.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load test data and \n",
    "batch = loader.get_batch(batch_size, 'test')\n",
    "\n",
    "tensors = [vgg_fcn.pred_up]\n",
    "feed_dict = {images: batch['images'], labels: batch['seg_labels']}\n",
    "\n",
    "# forward network to obtain segmentation result\n",
    "score  = sess.run(tensors, feed_dict=feed_dict)\n",
    "\n",
    "for bi in range(batch_size):\n",
    "    plot_result(batch['images'][bi], batch['seg_maps'][bi], score[0][bi], loader.get_palette())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict segmentation labels for all test examples\n",
    "# and compute confusion matrix\n",
    "num_classes = 22\n",
    "num_iterations = loader.get_num_test_examples() / batch_size\n",
    "conf_counts = np.zeros((num_classes, num_classes))\n",
    "\n",
    "loader.reset()\n",
    "for ii in range(int(num_iterations)):\n",
    "    # Load a batch data\n",
    "    batch = loader.get_batch(batch_size, 'test')\n",
    "    feed_dict = {images: batch['images'], labels: batch['seg_labels']}\n",
    "\n",
    "    # Run the optimizer\n",
    "    score = sess.run(vgg_fcn.pred_up, feed_dict=feed_dict)\n",
    "\n",
    "    # Accumulate confusions\n",
    "    for bi in range(batch_size):\n",
    "        # Do not count boundary labels\n",
    "        loc = np.where(batch['seg_labels'][bi] < 21, True, False)\n",
    "        # row is gt labels and column is predicted labels\n",
    "        sumim = batch['seg_labels'][bi] + score[bi] * num_classes\n",
    "        hs, bin_edge = np.histogram(sumim[loc], np.arange(num_classes*num_classes+1), \n",
    "                                    (0, num_classes*num_classes+1))\n",
    "        conf_counts = conf_counts + np.reshape(hs, (num_classes,num_classes))\n",
    "    \n",
    "    # Print the accuracy and loss of current batch data\n",
    "    if ((ii+1) % 10 == 0) or ((ii+1) == num_iterations):\n",
    "        print('TEST %d/%d Done' % (ii+1, num_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute accuracy for all classes and mean accuracy \n",
    "acc = np.zeros(num_classes)\n",
    "for ic in range(num_classes):\n",
    "    gt1 = np.sum(conf_counts[ic,:])\n",
    "    res1 = np.sum(conf_counts[:,ic])\n",
    "    gtlres = conf_counts[ic,ic]\n",
    "    acc[ic] = 100.0 * gtlres / (gt1 + res1 - gtlres)\n",
    "    if (ic > 0) and (ic < num_classes-1):\n",
    "        print('%s accuracy %.3f' % (class_names[ic-1], acc[ic]))\n",
    "print('Mean accuracy %.3f' % (np.mean(acc[1:num_classes])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
