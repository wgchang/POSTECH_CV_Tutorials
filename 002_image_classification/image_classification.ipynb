{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# pylint: disable=missing-docstring\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# own python codes\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from utils.utils import *\n",
    "from utils.tf_utils import *\n",
    "from cifar10_loader import CIFAR10_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This TensorFlow tutorial is written based on https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10, which is the tutorial for the image classification task on CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 튜토리얼에서는 CIFAR-10 dataset에서 간단한 convolutional 네트워크를 통한 object classification을 하는 방법을 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = 'cifar10_data'\n",
    "data_url = 'http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "maybe_download_and_extract(data_url, data_dir, 'cifar-10-batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loader and check the CIFAR-10 dataset\n",
    "위에서 다운받은 데이터를 batch 단위로 읽어올 수 있는 data loader class를 선언. 현재 data loader는 get_batch()를 통해 단순히 이미지 및 레이블을 batch 크기만큼 받아올 수 있으며, 이미지는 특별한 preprocessing을 하지는 않는다.\n",
    "하지만 보통 더 높은 성능을 위해서 random crop, flipping 등의 preprocessing을 하는 편이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loader = CIFAR10_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for constructing model (graph)\n",
    "Object classification을 위한 convolutional 네트워크를 선언하자. 네트워크를 선언하는 코딩 스타일은 사람마다 다르나 보통 아래와 같이 5부분 (input, model, loss, optimizer, accuracy)으로 나눠서 선언하는 경우가 많다. \n",
    " - build_inputs(): 네트워크의 인풋을 placeholder로 선언하는 함수\n",
    " - build_model(): 네트워크의 실제 연산을 담당하는 부분으로 2개의 convolutional layer 및 2개의 fully connected layer와 classification layer로 구성된다.\n",
    " - build_loss(): 학습을 위한 loss를 정의하며 여기에서는 cross-entropy loss를 사용한다.\n",
    " - build_train_operation(): 학습을 위한 파라미터들의 gradient 계산 및 파라미터 업데이트를 하는 optimizer를 정의. 여기에서는 Adam optimizer를 사용한다.\n",
    " - build_accuracy(): 테스트를 위하여 accuracry를 정의."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get variable initialization function\n",
    "initializer = get_initializer('normal', **{'stddev':0.01})\n",
    "\n",
    "def build_inputs(batch_size, image_size):\n",
    "    \"\"\" Construct input for CIFAR evaluation using the Reader ops.\n",
    "    Args:\n",
    "        batch_size: Batch size.\n",
    "        image_size: Image size.\n",
    "    Returns:\n",
    "        images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "        labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('inputs') as scope:\n",
    "        images = tf.placeholder(dtype=tf.float32, shape=[batch_size, image_size, image_size, 3],\n",
    "                               name='images')\n",
    "        labels = tf.placeholder(dtype=tf.int64, shape=[batch_size], name='labels')\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def build_model(images, batch_size):\n",
    "    \"\"\" Build the CIFAR-10 model consists of 2 convolutional, 2 fully connected and\n",
    "    1 classification layer.\n",
    "    Args:\n",
    "        images: Images returned from build_inputs(). 4-D tensor.\n",
    "    Returns:\n",
    "        Logits.\n",
    "    \"\"\"\n",
    "    \n",
    "    # conv1\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        conv1 = get_conv2D_layer(images, 3, 64, 5, 1, initializer, 0.0, \n",
    "                                 'relu', scope, True)\n",
    "\n",
    "    # pool1\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                         padding='SAME', name='pool1')\n",
    "    # norm1\n",
    "    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm1')\n",
    "\n",
    "    # conv2\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        conv2 = get_conv2D_layer(norm1, 64, 64, 5, 1, initializer, 0.0, \n",
    "                                 'relu', scope, True)\n",
    "\n",
    "    # norm2\n",
    "    norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm2')\n",
    "    # pool2\n",
    "    pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],\n",
    "                         strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "\n",
    "    # fc1\n",
    "    with tf.variable_scope('fc1') as scope:\n",
    "        fc1 = get_fully_connected_layer(pool2, -1, 384, initializer, 0.004, 'relu', \n",
    "                                        True, batch_size, scope, True)\n",
    "\n",
    "    # fc2\n",
    "    with tf.variable_scope('fc2') as scope:\n",
    "        fc2 = get_fully_connected_layer(fc1, 384, 192, initializer, 0.004, 'relu', \n",
    "                                        False, -1, scope, True)\n",
    "\n",
    "    # We don't apply softmax here because tf.nn.sparse_softmax_cross_entropy_with_logits \n",
    "    # accepts the unscaled logits and performs the softmax internally for efficiency.\n",
    "    with tf.variable_scope('logits') as scope:\n",
    "        logits = get_fully_connected_layer(fc2, 192, loader.get_num_classes(), initializer, \n",
    "                                           0.0, 'None', False, -1, scope, True)\n",
    "\n",
    "    return logits\n",
    "\n",
    "def build_loss(logits, labels):\n",
    "    \"\"\" Add L2Loss to all the trainable variables.\n",
    "    Add summary for \"Loss\" and \"Loss/avg\".\n",
    "    Args:\n",
    "        logits: Logits from build_model().\n",
    "        labels: Labels from build_inputs(). 1-D tensor.\n",
    "    Returns:\n",
    "        Loss tensor of type float.\n",
    "    \"\"\"\n",
    "    # Calculate the average cross entropy loss across the batch.\n",
    "    labels = tf.cast(labels, tf.int64)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=labels, logits=logits, name='cross_entropy_per_example')\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "    tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "    # The total loss is defined as the cross entropy loss plus all \n",
    "    # of the weight decay terms (L2 loss).\n",
    "    return tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "\n",
    "def build_train_operation(total_loss, params):\n",
    "    \"\"\" Train CIFAR-10 model and create an optimizer.\n",
    "    Args:\n",
    "        total_loss: Total loss from loss().\n",
    "        params: parameters for exponential decaying. \n",
    "                The learning rate is computed by \n",
    "                decayed_learning_rate = initial_lr * \n",
    "                    decay_rate ^ (global_step / decay_steps)\n",
    "            - initial_lr: initial learning rate\n",
    "            - decay_step: decay step\n",
    "            - decay_rate: decay rate\n",
    "    Returns:\n",
    "        train_op: op for training.\n",
    "        global_step: global step counting iteration\n",
    "    \"\"\"\n",
    "    # Decay the learning rate exponentially based on the number of steps.\n",
    "    global_step = tf.Variable(initial_value=0, name='global_step', trainable=False)\n",
    "    lr = tf.train.exponential_decay(params['initial_lr'],\n",
    "                                    global_step,\n",
    "                                    params['decay_step'],\n",
    "                                    params['decay_rate'],\n",
    "                                    staircase=True)\n",
    "    \n",
    "    # Create the optimizer which will minimize the loss.\n",
    "    # Below two methods are equivalent. But, when you want to process\n",
    "    # the gradients before updating a model, second method is appropriate.\n",
    "    if params['use_minimize']:\n",
    "        train_op = tf.train.AdamOptimizer(lr).minimize(total_loss, global_step=global_step)\n",
    "        return train_op, global_step\n",
    "    else:\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "        # Compute the gradients\n",
    "        grads_and_vars = optimizer.compute_gradients(total_loss)\n",
    "        # TODO: clipping the gradients\n",
    "        \n",
    "        # Updating the model\n",
    "        train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "        \n",
    "        return train_op, global_step, grads_and_vars\n",
    "    \n",
    "\n",
    "def build_accuracy(logits, labels):\n",
    "    \"\"\" Accuarcy computed by\n",
    "        accuracy = # of correct examples / # of total examples\n",
    "    Args:\n",
    "        logits: Logits from build_model().\n",
    "        labels: Labels from build_model().\n",
    "    Returns:\n",
    "        accuracy: Accuracy.\n",
    "        correct_num: The number of corrected examples\n",
    "    \"\"\"\n",
    "    pred_labels = tf.argmax(logits, axis=1)\n",
    "    correct_prediction = tf.equal(pred_labels, tf.cast(labels, tf.int64))\n",
    "    correct_num = tf.reduce_sum(tf.cast(correct_prediction, tf.float32))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    return accuracy, correct_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 학습을 위한 파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "init_from = '' # checkpoint path\n",
    "save_path = 'cifar10_checkpoints/cifar10_cnn'\n",
    "if not os.path.exists('cifar10_checkpoints'): os.makedirs('cifar10_checkpoints')\n",
    "batch_size = 100\n",
    "num_epochs = 50\n",
    "iteration_per_epoch = int(math.floor(loader.get_num_train_examples() / batch_size))\n",
    "save_checkpoint_frequency = 2500\n",
    "print_frequency = 100\n",
    "\n",
    "# Model updating parameters\n",
    "lr_params = {}\n",
    "lr_params['initial_lr'] = 0.001\n",
    "lr_params['decay_step'] = 1500 # 3 epoch assuming that the batch size is 100\n",
    "lr_params['decay_rate'] = 0.8\n",
    "lr_params['use_minimize'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n",
    "\n",
    "# build input placeholders\n",
    "images, labels = build_inputs(batch_size, loader.get_image_size())\n",
    "\n",
    "# Build a Graph that computes the logits predictions from the\n",
    "# inference model.\n",
    "logits = build_model(images, batch_size)\n",
    "\n",
    "# Calculate loss.\n",
    "loss = build_loss(logits, labels)\n",
    "\n",
    "# Build a Graph that trains the model with one batch of examples and\n",
    "# updates the model parameters.\n",
    "if lr_params['use_minimize']:\n",
    "    train_op, global_step = build_train_operation(loss, lr_params)\n",
    "else:\n",
    "    train_op, global_step, grads_vars = build_train_operation(loss, lr_params)\n",
    "\n",
    "# Build the accuracy and correct number of examples\n",
    "# to check model is learned correctly while training\n",
    "accuracy, correct_num = build_accuracy(logits, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 저장하고 추후 읽어오기 위한 saver를 정의하고, 모델을 실행 할 session을 생성 및 모델의 weight를 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Saver-object to save and reload the model later\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Create session\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,log_device_placement=True))\n",
    "\n",
    "# Initialize the variables\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정의한 모델을 구성하는 layer 및 그 name을 확인하는 방법을 알아보자. 또한, 특정 variable을 얻고 그 값을 확인하는 방법을 알아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of variables (or layers) in the model:\n",
      "Tensor(\"conv1/weights/read:0\", shape=(5, 5, 3, 64), dtype=float32)\n",
      "Tensor(\"conv1/biases/read:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"conv2/weights/read:0\", shape=(5, 5, 64, 64), dtype=float32)\n",
      "Tensor(\"conv2/biases/read:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"fc1/weights/read:0\", shape=(4096, 384), dtype=float32)\n",
      "Tensor(\"fc1/biases/read:0\", shape=(384,), dtype=float32)\n",
      "Tensor(\"fc2/weights/read:0\", shape=(384, 192), dtype=float32)\n",
      "Tensor(\"fc2/biases/read:0\", shape=(192,), dtype=float32)\n",
      "Tensor(\"logits/weights/read:0\", shape=(192, 10), dtype=float32)\n",
      "Tensor(\"logits/biases/read:0\", shape=(10,), dtype=float32)\n",
      "Tensor(\"global_step/read:0\", shape=(), dtype=int32)\n",
      "Tensor(\"beta1_power/read:0\", shape=(), dtype=float32)\n",
      "Tensor(\"beta2_power/read:0\", shape=(), dtype=float32)\n",
      "Tensor(\"conv1/weights/Adam/read:0\", shape=(5, 5, 3, 64), dtype=float32)\n",
      "Tensor(\"conv1/weights/Adam_1/read:0\", shape=(5, 5, 3, 64), dtype=float32)\n",
      "Tensor(\"conv1/biases/Adam/read:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"conv1/biases/Adam_1/read:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"conv2/weights/Adam/read:0\", shape=(5, 5, 64, 64), dtype=float32)\n",
      "Tensor(\"conv2/weights/Adam_1/read:0\", shape=(5, 5, 64, 64), dtype=float32)\n",
      "Tensor(\"conv2/biases/Adam/read:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"conv2/biases/Adam_1/read:0\", shape=(64,), dtype=float32)\n",
      "Tensor(\"fc1/weights/Adam/read:0\", shape=(4096, 384), dtype=float32)\n",
      "Tensor(\"fc1/weights/Adam_1/read:0\", shape=(4096, 384), dtype=float32)\n",
      "Tensor(\"fc1/biases/Adam/read:0\", shape=(384,), dtype=float32)\n",
      "Tensor(\"fc1/biases/Adam_1/read:0\", shape=(384,), dtype=float32)\n",
      "Tensor(\"fc2/weights/Adam/read:0\", shape=(384, 192), dtype=float32)\n",
      "Tensor(\"fc2/weights/Adam_1/read:0\", shape=(384, 192), dtype=float32)\n",
      "Tensor(\"fc2/biases/Adam/read:0\", shape=(192,), dtype=float32)\n",
      "Tensor(\"fc2/biases/Adam_1/read:0\", shape=(192,), dtype=float32)\n",
      "Tensor(\"logits/weights/Adam/read:0\", shape=(192, 10), dtype=float32)\n",
      "Tensor(\"logits/weights/Adam_1/read:0\", shape=(192, 10), dtype=float32)\n",
      "Tensor(\"logits/biases/Adam/read:0\", shape=(10,), dtype=float32)\n",
      "Tensor(\"logits/biases/Adam_1/read:0\", shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('The list of variables (or layers) in the model:')\n",
    "for var in tf.global_variables():\n",
    "    print(var)\n",
    "    #print(var.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 10)\n",
      "[ 0.0014041  -0.00409657 -0.00401915  0.00167214  0.00643379  0.01844599\n",
      "  0.01083519 -0.00677942 -0.00396929 -0.00309284]\n"
     ]
    }
   ],
   "source": [
    "logit_weight = tf.get_default_graph().get_tensor_by_name('logits/weights/read:0')\n",
    "logit = logit_weight.eval(session=sess)\n",
    "print(logit.shape)\n",
    "print(logit[0,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for ie in range(num_epochs):\n",
    "    for ii in range(iteration_per_epoch):\n",
    "        # Load a batch data\n",
    "        batch = loader.get_batch(batch_size, 'train')\n",
    "\n",
    "        # Run the optimizer\n",
    "        iteration, _ = sess.run([global_step, train_op], \n",
    "                                             feed_dict={images:batch['images'],\n",
    "                                                        labels:batch['labels']})\n",
    "\n",
    "        # Print the accuracy and loss of current batch data\n",
    "        if iteration % print_frequency == 0:\n",
    "            batch_loss, batch_acc = sess.run([loss, accuracy], \n",
    "                                             feed_dict={images:batch['images'],\n",
    "                                                        labels:batch['labels']})\n",
    "            print('%d Epoch %d iteration - Loss (%.3f) Accuracy (%.3f)' \n",
    "                      %(ie, ii, batch_loss, batch_acc))\n",
    "\n",
    "        # Save checkpoint\n",
    "        if iteration % save_checkpoint_frequency == 0:\n",
    "            saver.save(sess, save_path=save_path, global_step=global_step)\n",
    "            print('Saved checkpoint %s_%d' % (save_path, iteration))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last checkpoint path is cifar10_checkpoints/cifar10_cnn-25000\n"
     ]
    }
   ],
   "source": [
    "# Manually set the checkpoint path\n",
    "#checkpoint_path = 'cifar10_checkpoints/cifar10_cnn-5000'\n",
    "# Automatically find the last checkpoint\n",
    "checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir='cifar10_checkpoints/')\n",
    "print('Last checkpoint path is %s' % (checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is restored from cifar10_checkpoints/cifar10_cnn-25000\n",
      "Test accuracy: 71.03%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Evaluation model\"\"\"\n",
    "with tf.Graph().as_default():\n",
    "    # build input placeholders\n",
    "    images, labels = build_inputs(batch_size, loader.get_image_size())\n",
    "\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    logits = build_model(images, batch_size)\n",
    "\n",
    "    # Calculate loss.\n",
    "    loss = build_loss(logits, labels)\n",
    "\n",
    "    # Build a Graph that trains the model with one batch of examples and\n",
    "    # updates the model parameters.\n",
    "    train_op, global_step = build_train_operation(loss, lr_params)\n",
    "    \n",
    "    # Build the accuracy and correct number of examples\n",
    "    # to check model is learned correctly while training\n",
    "    accuracy, correct_num = build_accuracy(logits, labels)\n",
    "\n",
    "    # Create Saver-object to save and reload the model later\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
    "                                         log_device_placement=True)) as sess:\n",
    "        # Load the checkpoint or initialize the variables\n",
    "        if checkpoint_path != '':\n",
    "            saver.restore(sess, save_path=checkpoint_path)\n",
    "            print('Model is restored from %s' % checkpoint_path)\n",
    "        else:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Evaluate the model\n",
    "        num_correct = 0\n",
    "        num_examples = 0    \n",
    "        while True:\n",
    "            # Load a batch data\n",
    "            batch = loader.get_batch(batch_size, 'test')\n",
    "            if batch['wrapped']: break\n",
    "\n",
    "            # Compute the correct numbers\n",
    "            batch_acc, batch_correct_num = sess.run([accuracy, correct_num], \n",
    "                                                feed_dict={images:batch['images'],\n",
    "                                                           labels:batch['labels']})\n",
    "\n",
    "            num_correct += batch_correct_num\n",
    "            num_examples += batch_size\n",
    "        print('Test accuracy: %.2f%%' % (num_correct / num_examples * 100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
